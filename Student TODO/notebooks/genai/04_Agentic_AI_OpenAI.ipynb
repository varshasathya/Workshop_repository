{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4b4812",
   "metadata": {},
   "source": [
    "\n",
    "# Session 4 — Agentic AI (OpenAI): From Retrieval to Action\n",
    "\n",
    "This lab upgrades the agent from a local model to **OpenAI**.  \n",
    "You will connect an LLM to three tools and watch it *think → choose a tool → act → answer*.\n",
    "\n",
    "**Tools available**\n",
    "- `campus_retriever`: searches your existing RAG index (no rebuild)\n",
    "- `calculator`: safe math\n",
    "- `weather_live`: real weather via the free wttr.in API\n",
    "\n",
    "> Keep your `data/` folder from Session 3 (must contain `chunks.json` and `embeddings.npy`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd47805",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup (run once)\n",
    "Install agent + OpenAI bindings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Transformers to use PyTorch backend only\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_TF'] = '1'\n",
    "os.environ['USE_TF'] = '0'\n",
    "print(\"Set TRANSFORMERS_NO_TF and USE_TF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafe0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install langchain langchain-openai sentence-transformers faiss-cpu transformers requests tiktoken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea396445",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Configure your OpenAI API key\n",
    "Paste your key below (it only lives in this runtime). If already set in environment, this will detect it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "key = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "if not key:\n",
    "    try:\n",
    "        from getpass import getpass\n",
    "        key = getpass(\"Enter your OPENAI_API_KEY (input hidden): \")\n",
    "    except Exception:\n",
    "        key = input(\"Enter your OPENAI_API_KEY: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = (key or \"\").strip()\n",
    "print(\"OpenAI key configured.\" if key else \"⚠️ No key detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27157075",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load the existing RAG knowledge base\n",
    "We reuse the embeddings and chunks from Lab 3 — no re-chunking and no re-embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json, numpy as np, faiss, os\n",
    "\n",
    "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "assert os.path.exists(\"data/chunks.json\"), \"Missing data/chunks.json (run Session 3 first).\"\n",
    "assert os.path.exists(\"data/embeddings.npy\"), \"Missing data/embeddings.npy (run Session 3 first).\"\n",
    "\n",
    "embedder = SentenceTransformer(EMBED_MODEL_NAME)\n",
    "chunks = json.load(open(\"data/chunks.json\",\"r\",encoding=\"utf-8\"))\n",
    "emb = np.load(\"data/embeddings.npy\")\n",
    "\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "index.add(emb)\n",
    "\n",
    "print(f\"Loaded {len(chunks)} chunks, embedding dim={emb.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670d199",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Define the tools\n",
    "- Retriever: semantic search over your campus guide  \n",
    "- Calculator: safe eval with `sqrt` allowed  \n",
    "- Weather (live): free endpoint from wttr.in (no key needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.tools import tool\n",
    "import requests\n",
    "from math import sqrt\n",
    "\n",
    "@tool(\"campus_retriever\")\n",
    "def campus_retriever(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant campus info from the indexed knowledge base.\"\"\"\n",
    "    qv = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    scores, idxs = index.search(qv, 4)\n",
    "    ctx = []\n",
    "    for i in idxs[0]:\n",
    "        if int(i) < 0: \n",
    "            continue\n",
    "        ctx.append(chunks[int(i)]['text'])\n",
    "    return \"\\n\\n\".join(ctx)\n",
    "\n",
    "@tool(\"calculator\")\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Safely evaluate simple math (use +,-,*,/, sqrt()).\"\"\"\n",
    "    try:\n",
    "        out = eval(expression, {\"sqrt\": sqrt, \"__builtins__\": {}})\n",
    "        return str(out)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "@tool(\"weather_live\")\n",
    "def weather_live(city: str) -> str:\n",
    "    \"\"\"Fetch live weather using wttr.in (no API key). Return one-line summary.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(f\"https://wttr.in/{city}?format=3\", timeout=6)\n",
    "        return r.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching weather: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e19a7",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Initialize the OpenAI LLM\n",
    "We use `gpt-4o-mini` with low temperature for grounded answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "tools = [campus_retriever, calculator, weather_live]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  # ReAct: think -> act -> observe\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Agent ready (OpenAI + tools).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c8c8d",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Demo — watch the agent think and act\n",
    "You will see the ReAct trace in the output: Thought → Action → Observation → Answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c33f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tests = [\n",
    "    \"What are the library hours?\",\n",
    "    \"What is 15 squared plus 10?\",\n",
    "    \"What's the weather like in Bangalore?\",\n",
    "    \"Find the sports complex hours and also tell me if it's likely to be hot in Chennai today.\"\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    print(\"\\n🧠 Query:\", q)\n",
    "    print(\"-\"*72)\n",
    "    ans = agent.run(q)\n",
    "    print(\"🤖 Final Answer:\", ans)\n",
    "    print(\"-\"*72)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10a4df",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Mini chat loop (optional)\n",
    "Type your own questions. Type `exit` to stop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    try:\n",
    "        q = input(\"You: \")\n",
    "    except EOFError:\n",
    "        break\n",
    "    if q.strip().lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Bye!\")\n",
    "        break\n",
    "    try:\n",
    "        print(\"Agent:\", agent.run(q))\n",
    "    except Exception as e:\n",
    "        print(\"Agent error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd263d",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Teaching notes\n",
    "- OpenAI is a drop-in replacement that improves reasoning quality for agent demos.\n",
    "- Temperature 0.2–0.4 is ideal for factual tasks; increase for creative writing.\n",
    "- We reused the exact Session 3 index to show modular design.\n",
    "- Discuss safety: tool limits, API quotas, prompt logging, privacy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
